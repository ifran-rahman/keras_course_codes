{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a61d2c87",
   "metadata": {},
   "source": [
    "Reference :\n",
    "Dataset : https://github.com/rgbnihal2/COVID-19-X-ray-Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "286caf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d7ce2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto(gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.8)\n",
    "#device_count = {'GPU': 1}\n",
    ")\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01273541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffea53c1",
   "metadata": {},
   "source": [
    "Now we'll rearrange the images. Devide them into three folders train, validation, test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d186291",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('E:/DeepLearning/Datasets/COVID-19-X-ray-Dataset-master')\n",
    "if os.path.isdir('train/covid') is False:\n",
    "    os.makedirs('train/covid')\n",
    "    os.makedirs('train/normal')\n",
    "    os.makedirs('valid/covid')\n",
    "    os.makedirs('valid/normal')\n",
    "    os.makedirs('test/covid')\n",
    "    os.makedirs('test/normal')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b84872",
   "metadata": {},
   "source": [
    "We'll copy images to related folders. First we'll maintain a ration of, <br>\n",
    "80% train, 10% val, 10% test. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9daf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('E:/DeepLearning/Datasets/COVID-19-X-ray-Dataset-master')\n",
    "\n",
    "for i in random.sample(glob.glob('E:/DeepLearning/Datasets/COVID-19-X-ray-Dataset-master/COVID_Test*'),219):\n",
    "    shutil.move(i, 'E:/DeepLearning/Datasets/COVID-19-X-ray-Dataset-master/train/covid')\n",
    "for i in random.sample(glob.glob('E:/DeepLearning/Datasets/COVID-19-X-ray-Dataset-master/NORMAL_Test*'),219):\n",
    "    shutil.move(i, 'E:/DeepLearning/Datasets/COVID-19-X-ray-Dataset-master/train/normal')\n",
    "for i in random.sample(glob.glob('E:/DeepLearning/Datasets/COVID-19-X-ray-Dataset-master/COVID_Test*'), 28):\n",
    "    shutil.move(i, 'E:/DeepLearning/Datasets/COVID-19-X-ray-Dataset-master/valid/covid')\n",
    "for i in random.sample(glob.glob('E:/DeepLearning/Datasets/COVID-19-X-ray-Dataset-master/NORMAL_Test*'), 28):\n",
    "    shutil.move(i, 'E:/DeepLearning/Datasets/COVID-19-X-ray-Dataset-master/valid/normal')\n",
    "for i in random.sample(glob.glob('E:/DeepLearning/Datasets/COVID-19-X-ray-Dataset-master/COVID_Test*'), 26):\n",
    "    shutil.move(i, 'E:/DeepLearning/Datasets/COVID-19-X-ray-Dataset-master/test/covid')\n",
    "for i in random.sample(glob.glob('E:/DeepLearning/Datasets/COVID-19-X-ray-Dataset-master/NORMAL_Test*'), 26):\n",
    "    shutil.move(i, 'E:/DeepLearning/Datasets/COVID-19-X-ray-Dataset-master/test/normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "160ce532",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'E:/DeepLearning/Datasets/COVID-19-X-ray-Dataset-master/train'\n",
    "valid_path = 'E:/DeepLearning/Datasets/COVID-19-X-ray-Dataset-master/valid'\n",
    "test_path = 'E:/DeepLearning/Datasets/COVID-19-X-ray-Dataset-master/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e4f1ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 438 images belonging to 2 classes.\n",
      "Found 56 images belonging to 2 classes.\n",
      "Found 52 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(224,224), classes=['covid', 'normal'], batch_size=10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(224,224), classes=['covid', 'normal'], batch_size=10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(224,224), classes=['covid', 'normal'], batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019464bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(train_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9956a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plotImages(imgs)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0f1f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding = 'same', input_shape=(224,224,3)),\n",
    "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding = 'same'),\n",
    "    MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "    Flatten(),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cac74a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e062b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=train_batches,\n",
    "    validation_data=valid_batches,\n",
    "    validation_steps=len(valid_batches),\n",
    "    epochs=10,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311aab15",
   "metadata": {},
   "source": [
    "### Predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b872cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs, test_labels = next(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834421aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a888ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImages(test_imgs)\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e7b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x = test_batches, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a22d665",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63bc023",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true=test_batches.classes, y_pred= np.argmax(predictions, axis= -1)  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cea50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97798b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_labels = ['covid','normal']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7117f12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/Covid19_Classification_from_X-RAY _Images_normal_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df77105",
   "metadata": {},
   "source": [
    "### Train with MobileNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3053656c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 438 images belonging to 2 classes.\n",
      "Found 56 images belonging to 2 classes.\n",
      "Found 52 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(224,224), classes=['covid', 'normal'], batch_size=10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.mobilenet.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(224,224), classes=['covid', 'normal'], batch_size=10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(224,224), classes=['covid', 'normal'], batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb120365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 6s 1us/step\n"
     ]
    }
   ],
   "source": [
    "IMG_SHAPE = (224, 224, 3) \n",
    "base_model = tf.keras.applications.MobileNetV2( #grabbing pretrained neural network of choice\n",
    "    input_shape=IMG_SHAPE,\n",
    "    include_top=False, #this will freeze all the weights, because we dont have to retrain and change the weights, instead just add on to the MobileNetV2 CNN, so it clasiffies 5 classes instead of 80\n",
    "    weights='imagenet'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c395cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable=False #this freezes all the neurons for our base model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03473176",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([ #neural networks act in a sequence of layers, so we add layers as we want\n",
    "  base_model,\n",
    "  tf.keras.layers.Conv2D(32,3, activation = 'relu'), #This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. Bascially, it trying to understand the patterns of the image\n",
    "  tf.keras.layers.Dropout(0.2), #This layer prevents Neural Networks from Overfitting, i.e being too precise to a point where the NN is only able to recognize images that are present in the dataset\n",
    "  tf.keras.layers.GlobalAveragePooling2D(), #This layer calculates the average output of each feature map in the previous layer, thus reducing the data significantly and preparing the model for the final layer\n",
    "  tf.keras.layers.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a0d1087",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=mobile.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96eb58a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aac2f8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "44/44 - 30s - loss: 0.1840 - accuracy: 0.9201 - val_loss: 0.0178 - val_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "44/44 - 14s - loss: 0.0292 - accuracy: 0.9909 - val_loss: 0.0411 - val_accuracy: 0.9821\n",
      "Epoch 3/30\n",
      "44/44 - 13s - loss: 0.0104 - accuracy: 0.9977 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "44/44 - 14s - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "44/44 - 13s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "44/44 - 13s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "44/44 - 13s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "44/44 - 13s - loss: 8.5894e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "44/44 - 13s - loss: 6.5896e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "44/44 - 13s - loss: 5.9360e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "44/44 - 13s - loss: 4.1661e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "44/44 - 13s - loss: 3.7810e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "44/44 - 14s - loss: 4.5159e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "44/44 - 13s - loss: 3.6220e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "44/44 - 14s - loss: 2.6790e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "44/44 - 14s - loss: 2.4963e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "44/44 - 14s - loss: 2.6610e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "44/44 - 14s - loss: 2.3392e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "44/44 - 14s - loss: 1.9539e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "44/44 - 14s - loss: 2.0278e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "44/44 - 14s - loss: 1.8021e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "44/44 - 14s - loss: 1.6744e-04 - accuracy: 1.0000 - val_loss: 8.0877e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "44/44 - 14s - loss: 1.5292e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "44/44 - 13s - loss: 1.5736e-04 - accuracy: 1.0000 - val_loss: 7.9593e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "44/44 - 13s - loss: 1.3096e-04 - accuracy: 1.0000 - val_loss: 8.5270e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "44/44 - 14s - loss: 1.1727e-04 - accuracy: 1.0000 - val_loss: 9.0311e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "44/44 - 14s - loss: 1.1393e-04 - accuracy: 1.0000 - val_loss: 7.6509e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "44/44 - 14s - loss: 1.0914e-04 - accuracy: 1.0000 - val_loss: 6.7208e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "44/44 - 13s - loss: 1.0678e-04 - accuracy: 1.0000 - val_loss: 6.5347e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "44/44 - 14s - loss: 9.7659e-05 - accuracy: 1.0000 - val_loss: 5.9379e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x153c92a0910>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_batches,\n",
    "            validation_data=valid_batches,\n",
    "            validation_steps=len(valid_batches),\n",
    "            epochs=30,\n",
    "            verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c52049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
